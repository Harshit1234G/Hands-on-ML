{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading and Preprocessing Data with TensorFlow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:40.823493Z","iopub.execute_input":"2026-01-20T14:29:40.823857Z","iopub.status.idle":"2026-01-20T14:29:40.828574Z","shell.execute_reply.started":"2026-01-20T14:29:40.823824Z","shell.execute_reply":"2026-01-20T14:29:40.827521Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## The tf.data API","metadata":{}},{"cell_type":"code","source":"X = tf.range(36)\nX = tf.reshape(X, (6, 6))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:40.829835Z","iopub.execute_input":"2026-01-20T14:29:40.830121Z","iopub.status.idle":"2026-01-20T14:29:40.874103Z","shell.execute_reply.started":"2026-01-20T14:29:40.830090Z","shell.execute_reply":"2026-01-20T14:29:40.873161Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:40.875618Z","iopub.execute_input":"2026-01-20T14:29:40.875951Z","iopub.status.idle":"2026-01-20T14:29:40.898570Z","shell.execute_reply.started":"2026-01-20T14:29:40.875922Z","shell.execute_reply":"2026-01-20T14:29:40.897657Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(6, 6), dtype=int32, numpy=\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 6,  7,  8,  9, 10, 11],\n       [12, 13, 14, 15, 16, 17],\n       [18, 19, 20, 21, 22, 23],\n       [24, 25, 26, 27, 28, 29],\n       [30, 31, 32, 33, 34, 35]], dtype=int32)>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:40.900405Z","iopub.execute_input":"2026-01-20T14:29:40.900674Z","iopub.status.idle":"2026-01-20T14:29:40.926717Z","shell.execute_reply.started":"2026-01-20T14:29:40.900641Z","shell.execute_reply":"2026-01-20T14:29:40.925936Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:40.927627Z","iopub.execute_input":"2026-01-20T14:29:40.927923Z","iopub.status.idle":"2026-01-20T14:29:40.949777Z","shell.execute_reply.started":"2026-01-20T14:29:40.927877Z","shell.execute_reply":"2026-01-20T14:29:40.948837Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<_TensorSliceDataset element_spec=TensorSpec(shape=(6,), dtype=tf.int32, name=None)>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"tf.data.Dataset.range(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:40.950681Z","iopub.execute_input":"2026-01-20T14:29:40.950940Z","iopub.status.idle":"2026-01-20T14:29:40.979507Z","shell.execute_reply.started":"2026-01-20T14:29:40.950910Z","shell.execute_reply":"2026-01-20T14:29:40.978411Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<_RangeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"for item in dataset:\n    print(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:40.980765Z","iopub.execute_input":"2026-01-20T14:29:40.981113Z","iopub.status.idle":"2026-01-20T14:29:41.034996Z","shell.execute_reply.started":"2026-01-20T14:29:40.981084Z","shell.execute_reply":"2026-01-20T14:29:41.034011Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int32)\ntf.Tensor([ 6  7  8  9 10 11], shape=(6,), dtype=int32)\ntf.Tensor([12 13 14 15 16 17], shape=(6,), dtype=int32)\ntf.Tensor([18 19 20 21 22 23], shape=(6,), dtype=int32)\ntf.Tensor([24 25 26 27 28 29], shape=(6,), dtype=int32)\ntf.Tensor([30 31 32 33 34 35], shape=(6,), dtype=int32)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"X_nested = {'a': ([1, 2, 3], [4, 5, 6]), 'b': [7, 8, 9]}\nnested_dataset = tf.data.Dataset.from_tensor_slices(X_nested)\nfor item in nested_dataset:\n    print(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:41.035841Z","iopub.execute_input":"2026-01-20T14:29:41.036107Z","iopub.status.idle":"2026-01-20T14:29:41.282413Z","shell.execute_reply.started":"2026-01-20T14:29:41.036085Z","shell.execute_reply":"2026-01-20T14:29:41.281519Z"}},"outputs":[{"name":"stdout","text":"{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=4>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=7>}\n{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=8>}\n{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=6>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=9>}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Chaining Transformations","metadata":{}},{"cell_type":"code","source":"dataset.repeat(2).batch(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:41.283287Z","iopub.execute_input":"2026-01-20T14:29:41.283598Z","iopub.status.idle":"2026-01-20T14:29:41.295322Z","shell.execute_reply.started":"2026-01-20T14:29:41.283570Z","shell.execute_reply":"2026-01-20T14:29:41.294418Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<_BatchDataset element_spec=TensorSpec(shape=(None, 6), dtype=tf.int32, name=None)>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.map(lambda x: x * 2)\nfor item in dataset:\n    print(item)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:41.298158Z","iopub.execute_input":"2026-01-20T14:29:41.298434Z","iopub.status.idle":"2026-01-20T14:29:41.347699Z","shell.execute_reply.started":"2026-01-20T14:29:41.298409Z","shell.execute_reply":"2026-01-20T14:29:41.347058Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor([ 0  2  4  6  8 10], shape=(6,), dtype=int32)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"dataset = dataset.filter(lambda x: tf.reduce_sum(x) < 50)\nfor item in dataset:\n    print(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:41.348549Z","iopub.execute_input":"2026-01-20T14:29:41.348785Z","iopub.status.idle":"2026-01-20T14:29:41.397086Z","shell.execute_reply.started":"2026-01-20T14:29:41.348762Z","shell.execute_reply":"2026-01-20T14:29:41.396286Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor([ 0  2  4  6  8 10], shape=(6,), dtype=int32)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Shuffling the Data","metadata":{}},{"cell_type":"code","source":"dataset = tf.data.Dataset.range(10).repeat(2)\ndataset = dataset.shuffle(buffer_size= 4, seed= 42).batch(7)\nfor item in dataset:\n    print(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:41.397952Z","iopub.execute_input":"2026-01-20T14:29:41.398201Z","iopub.status.idle":"2026-01-20T14:29:41.427282Z","shell.execute_reply.started":"2026-01-20T14:29:41.398180Z","shell.execute_reply":"2026-01-20T14:29:41.426026Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor([1 4 2 3 5 0 6], shape=(7,), dtype=int64)\ntf.Tensor([9 8 2 0 3 1 4], shape=(7,), dtype=int64)\ntf.Tensor([5 7 9 6 7 8], shape=(6,), dtype=int64)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### Interleaving Lines from Multiple Files","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\n\nhousing = fetch_california_housing()\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    housing.data, housing.target.reshape(-1, 1), random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_train_full, y_train_full, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:41.428417Z","iopub.execute_input":"2026-01-20T14:29:41.428694Z","iopub.status.idle":"2026-01-20T14:29:44.155124Z","shell.execute_reply.started":"2026-01-20T14:29:41.428662Z","shell.execute_reply":"2026-01-20T14:29:44.154439Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import numpy as np\nfrom pathlib import Path\n\ndef save_to_csv_files(data, name_prefix, header=None, n_parts=10):\n    housing_dir = Path() / 'datasets' / 'housing'\n    housing_dir.mkdir(parents=True, exist_ok=True)\n    filename_format = 'my_{}_{:02d}.csv'\n\n    filepaths = []\n    m = len(data)\n    chunks = np.array_split(np.arange(m), n_parts)\n    for file_idx, row_indices in enumerate(chunks):\n        part_csv = housing_dir / filename_format.format(name_prefix, file_idx)\n        filepaths.append(str(part_csv))\n        with open(part_csv, 'w') as f:\n            if header is not None:\n                f.write(header)\n                f.write('\\n')\n            for row_idx in row_indices:\n                f.write(','.join([str(col) for col in data[row_idx]]))\n                f.write('\\n')\n    return filepaths\n\ntrain_data = np.c_[X_train, y_train]\nvalid_data = np.c_[X_valid, y_valid]\ntest_data = np.c_[X_test, y_test]\nheader_cols = housing.feature_names + ['MedianHouseValue']\nheader = ','.join(header_cols)\n\ntrain_filepaths = save_to_csv_files(train_data, 'train', header, n_parts=20)\nvalid_filepaths = save_to_csv_files(valid_data, 'valid', header, n_parts=10)\ntest_filepaths = save_to_csv_files(test_data, 'test', header, n_parts=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.155973Z","iopub.execute_input":"2026-01-20T14:29:44.156484Z","iopub.status.idle":"2026-01-20T14:29:44.266779Z","shell.execute_reply.started":"2026-01-20T14:29:44.156463Z","shell.execute_reply":"2026-01-20T14:29:44.265977Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(''.join(open(train_filepaths[0]).readlines()[:4]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.268088Z","iopub.execute_input":"2026-01-20T14:29:44.268416Z","iopub.status.idle":"2026-01-20T14:29:44.276644Z","shell.execute_reply.started":"2026-01-20T14:29:44.268384Z","shell.execute_reply":"2026-01-20T14:29:44.275949Z"}},"outputs":[{"name":"stdout","text":"MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"train_filepaths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.277442Z","iopub.execute_input":"2026-01-20T14:29:44.277628Z","iopub.status.idle":"2026-01-20T14:29:44.300206Z","shell.execute_reply.started":"2026-01-20T14:29:44.277609Z","shell.execute_reply":"2026-01-20T14:29:44.298994Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['datasets/housing/my_train_00.csv',\n 'datasets/housing/my_train_01.csv',\n 'datasets/housing/my_train_02.csv',\n 'datasets/housing/my_train_03.csv',\n 'datasets/housing/my_train_04.csv',\n 'datasets/housing/my_train_05.csv',\n 'datasets/housing/my_train_06.csv',\n 'datasets/housing/my_train_07.csv',\n 'datasets/housing/my_train_08.csv',\n 'datasets/housing/my_train_09.csv',\n 'datasets/housing/my_train_10.csv',\n 'datasets/housing/my_train_11.csv',\n 'datasets/housing/my_train_12.csv',\n 'datasets/housing/my_train_13.csv',\n 'datasets/housing/my_train_14.csv',\n 'datasets/housing/my_train_15.csv',\n 'datasets/housing/my_train_16.csv',\n 'datasets/housing/my_train_17.csv',\n 'datasets/housing/my_train_18.csv',\n 'datasets/housing/my_train_19.csv']"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.301336Z","iopub.execute_input":"2026-01-20T14:29:44.301629Z","iopub.status.idle":"2026-01-20T14:29:44.343071Z","shell.execute_reply.started":"2026-01-20T14:29:44.301605Z","shell.execute_reply":"2026-01-20T14:29:44.342307Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"for filepath in filepath_dataset:\n    print(filepath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.343999Z","iopub.execute_input":"2026-01-20T14:29:44.344277Z","iopub.status.idle":"2026-01-20T14:29:44.357610Z","shell.execute_reply.started":"2026-01-20T14:29:44.344250Z","shell.execute_reply":"2026-01-20T14:29:44.356805Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\ntf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"n_readers = 5\ndataset = filepath_dataset.interleave(\n    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n    cycle_length=n_readers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.358789Z","iopub.execute_input":"2026-01-20T14:29:44.359305Z","iopub.status.idle":"2026-01-20T14:29:44.398287Z","shell.execute_reply.started":"2026-01-20T14:29:44.359277Z","shell.execute_reply":"2026-01-20T14:29:44.397542Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"for line in dataset.take(5):\n    print(line)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.399168Z","iopub.execute_input":"2026-01-20T14:29:44.399441Z","iopub.status.idle":"2026-01-20T14:29:44.434933Z","shell.execute_reply.started":"2026-01-20T14:29:44.399413Z","shell.execute_reply":"2026-01-20T14:29:44.434006Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(b'4.5909,16.0,5.475877192982456,1.0964912280701755,1357.0,2.9758771929824563,33.63,-117.71,2.418', shape=(), dtype=string)\ntf.Tensor(b'2.4792,24.0,3.4547038327526134,1.1341463414634145,2251.0,3.921602787456446,34.18,-118.38,2.0', shape=(), dtype=string)\ntf.Tensor(b'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67', shape=(), dtype=string)\ntf.Tensor(b'2.1856,41.0,3.7189873417721517,1.0658227848101265,803.0,2.0329113924050635,32.76,-117.12,1.205', shape=(), dtype=string)\ntf.Tensor(b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215', shape=(), dtype=string)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Preprocessing the Data","metadata":{}},{"cell_type":"code","source":"mean, var = tf.nn.moments(X_train, axes= 0)\nmean = tf.cast(mean, tf.float32)\nstd = tf.cast(tf.sqrt(var), tf.float32)\nn_inputs = 8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.435933Z","iopub.execute_input":"2026-01-20T14:29:44.436264Z","iopub.status.idle":"2026-01-20T14:29:44.457619Z","shell.execute_reply.started":"2026-01-20T14:29:44.436237Z","shell.execute_reply":"2026-01-20T14:29:44.456970Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def parse_csv_line(line: str) -> tuple[tf.Tensor]:\n    # default values for initial 8 features is 0, and label is empty tensor (which raises an error)\n    defaults = [0.] * n_inputs + [tf.constant([], dtype= tf.float32)]\n    fields = tf.io.decode_csv(line, record_defaults= defaults)\n    return tf.stack(fields[:-1]), tf.stack(fields[-1:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.458359Z","iopub.execute_input":"2026-01-20T14:29:44.458594Z","iopub.status.idle":"2026-01-20T14:29:44.464566Z","shell.execute_reply.started":"2026-01-20T14:29:44.458565Z","shell.execute_reply":"2026-01-20T14:29:44.463785Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def preprocess(line: str) -> tuple[tf.Tensor]:\n    x, y = parse_csv_line(line)\n    return (x - mean) / std, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.465350Z","iopub.execute_input":"2026-01-20T14:29:44.465607Z","iopub.status.idle":"2026-01-20T14:29:44.488229Z","shell.execute_reply.started":"2026-01-20T14:29:44.465579Z","shell.execute_reply":"2026-01-20T14:29:44.486785Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.489417Z","iopub.execute_input":"2026-01-20T14:29:44.489704Z","iopub.status.idle":"2026-01-20T14:29:44.521478Z","shell.execute_reply.started":"2026-01-20T14:29:44.489677Z","shell.execute_reply":"2026-01-20T14:29:44.520385Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([ 0.16579159,  1.216324  , -0.05204564, -0.39215982, -0.5277444 ,\n        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"## Putting Everything Together + Prefetching","metadata":{}},{"cell_type":"code","source":"def csv_reader_dataset(\n    filepaths: list[str], \n    *, \n    n_readers: int = 5,\n    n_read_threads: int | None = None,\n    n_parse_threads: int = 5,\n    shuffle_buffer_size: int = 10_000,\n    seed: int = 42,\n    batch_size: int = 32\n) -> tf.data.Dataset:\n    dataset = tf.data.Dataset.list_files(filepaths, seed= seed)\n    dataset = dataset.interleave(\n        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n        cycle_length= n_readers, num_parallel_calls= n_read_threads)\n    dataset = dataset.map(preprocess, num_parallel_calls= n_parse_threads)\n    dataset = dataset.shuffle(shuffle_buffer_size, seed= seed)\n    return dataset.batch(batch_size).prefetch(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.522443Z","iopub.execute_input":"2026-01-20T14:29:44.522686Z","iopub.status.idle":"2026-01-20T14:29:44.534962Z","shell.execute_reply.started":"2026-01-20T14:29:44.522662Z","shell.execute_reply":"2026-01-20T14:29:44.533787Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"example_set = csv_reader_dataset(train_filepaths, batch_size= 3)\nfor X_batch, y_batch in example_set.take(2):\n    print('X =', X_batch)\n    print('y =', y_batch)\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.535963Z","iopub.execute_input":"2026-01-20T14:29:44.536186Z","iopub.status.idle":"2026-01-20T14:29:44.976782Z","shell.execute_reply.started":"2026-01-20T14:29:44.536167Z","shell.execute_reply":"2026-01-20T14:29:44.975554Z"}},"outputs":[{"name":"stdout","text":"X = tf.Tensor(\n[[-1.3957452  -0.04940685 -0.22830808  0.22648273  2.2593622   0.35200632\n   0.9667386  -1.4121602 ]\n [ 2.7112627  -1.0778131   0.69413143 -0.14870553  0.51810503  0.3507294\n  -0.82285154  0.80680597]\n [-0.13484643 -1.868895    0.01032507 -0.13787179 -0.12893449  0.03143518\n   0.2687057   0.13212144]], shape=(3, 8), dtype=float32)\ny = tf.Tensor(\n[[1.819]\n [3.674]\n [0.954]], shape=(3, 1), dtype=float32)\n\nX = tf.Tensor(\n[[ 0.09031774  0.9789995   0.1327582  -0.13753782 -0.23388447  0.10211545\n   0.97610843 -1.4121602 ]\n [ 0.05218809 -2.0271113   0.2940109  -0.02403445  0.16218767 -0.02844518\n   1.4117942  -0.93737936]\n [-0.672276    0.02970133 -0.76922584 -0.15086786  0.4962024  -0.02741998\n  -0.7853724   0.77182245]], shape=(3, 8), dtype=float32)\ny = tf.Tensor(\n[[2.725]\n [1.205]\n [1.625]], shape=(3, 1), dtype=float32)\n\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"for m in dir(tf.data.Dataset):\n    if not (m.startswith('_') or m.endswith('_')):\n        func = getattr(tf.data.Dataset, m)\n        if hasattr(func, '__doc__'):\n            print(f'● {f'{m}()':<27}{func.__doc__.split('\\n')[0]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.978069Z","iopub.execute_input":"2026-01-20T14:29:44.978356Z","iopub.status.idle":"2026-01-20T14:29:44.983750Z","shell.execute_reply.started":"2026-01-20T14:29:44.978334Z","shell.execute_reply":"2026-01-20T14:29:44.983041Z"}},"outputs":[{"name":"stdout","text":"● apply()                    Applies a transformation function to this dataset.\n● as_numpy_iterator()        Returns an iterator which converts all elements of the dataset to numpy.\n● batch()                    Combines consecutive elements of this dataset into batches.\n● bucket_by_sequence_length()A transformation that buckets elements in a `Dataset` by length.\n● cache()                    Caches the elements in this dataset.\n● cardinality()              Returns the cardinality of the dataset, if known.\n● choose_from_datasets()     Creates a dataset that deterministically chooses elements from `datasets`.\n● concatenate()              Creates a `Dataset` by concatenating the given dataset with this dataset.\n● counter()                  Creates a `Dataset` that counts from `start` in steps of size `step`.\n● element_spec()             The type specification of an element of this dataset.\n● enumerate()                Enumerates the elements of this dataset.\n● filter()                   Filters this dataset according to `predicate`.\n● fingerprint()              Computes the fingerprint of this `Dataset`.\n● flat_map()                 Maps `map_func` across this dataset and flattens the result.\n● from_generator()           Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n● from_tensor_slices()       Creates a `Dataset` whose elements are slices of the given tensors.\n● from_tensors()             Creates a `Dataset` with a single element, comprising the given tensors.\n● get_single_element()       Returns the single element of the `dataset`.\n● group_by_window()          Groups windows of elements by key and reduces them.\n● ignore_errors()            Drops elements that cause errors.\n● interleave()               Maps `map_func` across this dataset, and interleaves the results.\n● list_files()               A dataset of all files matching one or more glob patterns.\n● load()                     Loads a previously saved dataset.\n● map()                      Maps `map_func` across the elements of this dataset.\n● options()                  Returns the options for this dataset and its inputs.\n● padded_batch()             Combines consecutive elements of this dataset into padded batches.\n● prefetch()                 Creates a `Dataset` that prefetches elements from this dataset.\n● ragged_batch()             Combines consecutive elements of this dataset into `tf.RaggedTensor`s.\n● random()                   Creates a `Dataset` of pseudorandom values.\n● range()                    Creates a `Dataset` of a step-separated range of values.\n● rebatch()                  Creates a `Dataset` that rebatches the elements from this dataset.\n● reduce()                   Reduces the input dataset to a single element.\n● rejection_resample()       Resamples elements to reach a target distribution.\n● repeat()                   Repeats this dataset so each original value is seen `count` times.\n● sample_from_datasets()     Samples elements at random from the datasets in `datasets`.\n● save()                     Saves the content of the given dataset.\n● scan()                     A transformation that scans a function across an input dataset.\n● shard()                    Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n● shuffle()                  Randomly shuffles the elements of this dataset.\n● skip()                     Creates a `Dataset` that skips `count` elements from this dataset.\n● snapshot()                 API to persist the output of the input dataset.\n● sparse_batch()             Combines consecutive elements into `tf.sparse.SparseTensor`s.\n● take()                     Creates a `Dataset` with at most `count` elements from this dataset.\n● take_while()               A transformation that stops dataset iteration based on a `predicate`.\n● unbatch()                  Splits elements of a dataset into multiple elements.\n● unique()                   A transformation that discards duplicate elements of a `Dataset`.\n● window()                   Returns a dataset of \"windows\".\n● with_options()             Returns a new `tf.data.Dataset` with the given options set.\n● zip()                      Creates a `Dataset` by zipping together the given datasets.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## The TFRecord Format","metadata":{}},{"cell_type":"code","source":"with tf.io.TFRecordWriter('my_data.tfrecord') as f:\n    f.write(b'This is the first record')\n    f.write(b'And this is the second record')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:44.987032Z","iopub.execute_input":"2026-01-20T14:29:44.987289Z","iopub.status.idle":"2026-01-20T14:29:45.006703Z","shell.execute_reply.started":"2026-01-20T14:29:44.987267Z","shell.execute_reply":"2026-01-20T14:29:45.005470Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"filepaths = ['my_data.tfrecord']\ndataset = tf.data.TFRecordDataset(filepaths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.007659Z","iopub.execute_input":"2026-01-20T14:29:45.007918Z","iopub.status.idle":"2026-01-20T14:29:45.034938Z","shell.execute_reply.started":"2026-01-20T14:29:45.007869Z","shell.execute_reply":"2026-01-20T14:29:45.034101Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"for item in dataset:\n    print(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.035850Z","iopub.execute_input":"2026-01-20T14:29:45.036097Z","iopub.status.idle":"2026-01-20T14:29:45.054622Z","shell.execute_reply.started":"2026-01-20T14:29:45.036077Z","shell.execute_reply":"2026-01-20T14:29:45.053853Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(b'This is the first record', shape=(), dtype=string)\ntf.Tensor(b'And this is the second record', shape=(), dtype=string)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"options = tf.io.TFRecordOptions(compression_type='GZIP')\nwith tf.io.TFRecordWriter('my_compressed.tfrecord', options) as f:\n    f.write(b'Compress, compress, compress!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.055508Z","iopub.execute_input":"2026-01-20T14:29:45.055699Z","iopub.status.idle":"2026-01-20T14:29:45.060811Z","shell.execute_reply.started":"2026-01-20T14:29:45.055676Z","shell.execute_reply":"2026-01-20T14:29:45.059957Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"dataset = tf.data.TFRecordDataset(['my_compressed.tfrecord'],\n                                  compression_type='GZIP')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.061817Z","iopub.execute_input":"2026-01-20T14:29:45.062112Z","iopub.status.idle":"2026-01-20T14:29:45.095065Z","shell.execute_reply.started":"2026-01-20T14:29:45.062088Z","shell.execute_reply":"2026-01-20T14:29:45.093974Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## TensorFlow Protobufs","metadata":{}},{"cell_type":"code","source":"from tensorflow.train import BytesList, FloatList, Int64List\nfrom tensorflow.train import Feature, Features, Example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.095825Z","iopub.execute_input":"2026-01-20T14:29:45.096078Z","iopub.status.idle":"2026-01-20T14:29:45.102274Z","shell.execute_reply.started":"2026-01-20T14:29:45.096058Z","shell.execute_reply":"2026-01-20T14:29:45.101273Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"person_example = Example(\n    features= Features(\n        feature= {\n            'name': Feature(bytes_list= BytesList(value= [b'Alic'])),\n            'id': Feature(int64_list= Int64List(value= [123])),\n            'emails': Feature(bytes_list= BytesList(value= [b'a@b.com', b'c@a.com']))\n        }\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.103414Z","iopub.execute_input":"2026-01-20T14:29:45.103640Z","iopub.status.idle":"2026-01-20T14:29:45.120069Z","shell.execute_reply.started":"2026-01-20T14:29:45.103613Z","shell.execute_reply":"2026-01-20T14:29:45.119099Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"with tf.io.TFRecordWriter('my_contacts.tfrecord') as f:\n    for _ in range(5):\n        f.write(person_example.SerializeToString())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.121050Z","iopub.execute_input":"2026-01-20T14:29:45.121271Z","iopub.status.idle":"2026-01-20T14:29:45.137939Z","shell.execute_reply.started":"2026-01-20T14:29:45.121250Z","shell.execute_reply":"2026-01-20T14:29:45.136987Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"## Loading and Parsing examples","metadata":{}},{"cell_type":"code","source":"feature_description = {\n    'name': tf.io.FixedLenFeature([], tf.string, default_value= ''),\n    'id': tf.io.FixedLenFeature([], tf.int64, default_value= 0),\n    'emails': tf.io.VarLenFeature(tf.string)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.138787Z","iopub.execute_input":"2026-01-20T14:29:45.139086Z","iopub.status.idle":"2026-01-20T14:29:45.159073Z","shell.execute_reply.started":"2026-01-20T14:29:45.139058Z","shell.execute_reply":"2026-01-20T14:29:45.158066Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def parse(serialized_example):\n    return tf.io.parse_single_example(serialized_example, feature_description)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.160270Z","iopub.execute_input":"2026-01-20T14:29:45.160567Z","iopub.status.idle":"2026-01-20T14:29:45.180948Z","shell.execute_reply.started":"2026-01-20T14:29:45.160542Z","shell.execute_reply":"2026-01-20T14:29:45.180201Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"dataset = tf.data.TFRecordDataset(['my_contacts.tfrecord']).map(parse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.181800Z","iopub.execute_input":"2026-01-20T14:29:45.182033Z","iopub.status.idle":"2026-01-20T14:29:45.241783Z","shell.execute_reply.started":"2026-01-20T14:29:45.182010Z","shell.execute_reply":"2026-01-20T14:29:45.240981Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"for parsed_example in dataset.take(1):\n    print(parsed_example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.242695Z","iopub.execute_input":"2026-01-20T14:29:45.242953Z","iopub.status.idle":"2026-01-20T14:29:45.274289Z","shell.execute_reply.started":"2026-01-20T14:29:45.242925Z","shell.execute_reply":"2026-01-20T14:29:45.273115Z"}},"outputs":[{"name":"stdout","text":"{'emails': SparseTensor(indices=tf.Tensor(\n[[0]\n [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@a.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alic'>}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"tf.sparse.to_dense(parsed_example['emails'], default_value= b'')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.275808Z","iopub.execute_input":"2026-01-20T14:29:45.276111Z","iopub.status.idle":"2026-01-20T14:29:45.284087Z","shell.execute_reply.started":"2026-01-20T14:29:45.276082Z","shell.execute_reply":"2026-01-20T14:29:45.283250Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@a.com'], dtype=object)>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"parsed_example['emails'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.285058Z","iopub.execute_input":"2026-01-20T14:29:45.285314Z","iopub.status.idle":"2026-01-20T14:29:45.304383Z","shell.execute_reply.started":"2026-01-20T14:29:45.285286Z","shell.execute_reply":"2026-01-20T14:29:45.303319Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@a.com'], dtype=object)>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"def parse(serialized_examples):\n    return tf.io.parse_example(serialized_examples, feature_description)   # for all examples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.305290Z","iopub.execute_input":"2026-01-20T14:29:45.305511Z","iopub.status.idle":"2026-01-20T14:29:45.325952Z","shell.execute_reply.started":"2026-01-20T14:29:45.305492Z","shell.execute_reply":"2026-01-20T14:29:45.324969Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"dataset = tf.data.TFRecordDataset(['my_contacts.tfrecord']).batch(2).map(parse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.326797Z","iopub.execute_input":"2026-01-20T14:29:45.327109Z","iopub.status.idle":"2026-01-20T14:29:45.385181Z","shell.execute_reply.started":"2026-01-20T14:29:45.327012Z","shell.execute_reply":"2026-01-20T14:29:45.383974Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"for example in dataset:\n    print(example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.386437Z","iopub.execute_input":"2026-01-20T14:29:45.386709Z","iopub.status.idle":"2026-01-20T14:29:45.413854Z","shell.execute_reply.started":"2026-01-20T14:29:45.386685Z","shell.execute_reply":"2026-01-20T14:29:45.412908Z"}},"outputs":[{"name":"stdout","text":"{'emails': SparseTensor(indices=tf.Tensor(\n[[0 0]\n [0 1]\n [1 0]\n [1 1]], shape=(4, 2), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@a.com' b'a@b.com' b'c@a.com'], shape=(4,), dtype=string), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64)), 'id': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([123, 123])>, 'name': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Alic', b'Alic'], dtype=object)>}\n{'emails': SparseTensor(indices=tf.Tensor(\n[[0 0]\n [0 1]\n [1 0]\n [1 1]], shape=(4, 2), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@a.com' b'a@b.com' b'c@a.com'], shape=(4,), dtype=string), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64)), 'id': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([123, 123])>, 'name': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Alic', b'Alic'], dtype=object)>}\n{'emails': SparseTensor(indices=tf.Tensor(\n[[0 0]\n [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@a.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64)), 'id': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([123])>, 'name': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Alic'], dtype=object)>}\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"## Keras Preprocessing Layers\n### Discretization Layer","metadata":{}},{"cell_type":"code","source":"age = tf.constant([[10.], [93.], [57.], [18.], [37.], [5.]])\ndiscretize_layer = tf.keras.layers.Discretization(bin_boundaries= [18., 50.])\nage_categories = discretize_layer(age)\nage_categories","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.414795Z","iopub.execute_input":"2026-01-20T14:29:45.415095Z","iopub.status.idle":"2026-01-20T14:29:45.426639Z","shell.execute_reply.started":"2026-01-20T14:29:45.415072Z","shell.execute_reply":"2026-01-20T14:29:45.425430Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(6, 1), dtype=int64, numpy=\narray([[0],\n       [2],\n       [2],\n       [1],\n       [1],\n       [0]])>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"discretize_layer = tf.keras.layers.Discretization(num_bins= 3)\ndiscretize_layer.adapt(age)\nage_categories = discretize_layer(age)\nage_categories","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.427816Z","iopub.execute_input":"2026-01-20T14:29:45.428373Z","iopub.status.idle":"2026-01-20T14:29:45.454445Z","shell.execute_reply.started":"2026-01-20T14:29:45.428346Z","shell.execute_reply":"2026-01-20T14:29:45.453677Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(6, 1), dtype=int64, numpy=\narray([[1],\n       [2],\n       [2],\n       [1],\n       [2],\n       [0]])>"},"metadata":{}}],"execution_count":48},{"cell_type":"markdown","source":"### Category Encoding Layer","metadata":{}},{"cell_type":"code","source":"onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3)\nonehot_layer(age_categories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.455393Z","iopub.execute_input":"2026-01-20T14:29:45.455664Z","iopub.status.idle":"2026-01-20T14:29:45.486664Z","shell.execute_reply.started":"2026-01-20T14:29:45.455639Z","shell.execute_reply":"2026-01-20T14:29:45.485850Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\narray([[0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.]], dtype=float32)>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"two_age_categories = np.array([[1, 0], [2, 2], [2, 0]])\nonehot_layer(two_age_categories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.487553Z","iopub.execute_input":"2026-01-20T14:29:45.487769Z","iopub.status.idle":"2026-01-20T14:29:45.496830Z","shell.execute_reply.started":"2026-01-20T14:29:45.487749Z","shell.execute_reply":"2026-01-20T14:29:45.495706Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[1., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 1.]], dtype=float32)>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens= 3, output_mode= 'count')\nonehot_layer(two_age_categories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.497763Z","iopub.execute_input":"2026-01-20T14:29:45.498150Z","iopub.status.idle":"2026-01-20T14:29:45.522080Z","shell.execute_reply.started":"2026-01-20T14:29:45.498111Z","shell.execute_reply":"2026-01-20T14:29:45.521201Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[1., 1., 0.],\n       [0., 0., 2.],\n       [1., 0., 1.]], dtype=float32)>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens= 3 + 3)\nonehot_layer(two_age_categories + [0, 3])  # adds 3 to the second feature","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:29:45.523182Z","iopub.execute_input":"2026-01-20T14:29:45.523941Z","iopub.status.idle":"2026-01-20T14:29:45.545746Z","shell.execute_reply.started":"2026-01-20T14:29:45.523908Z","shell.execute_reply":"2026-01-20T14:29:45.544372Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3, 6), dtype=float32, numpy=\narray([[0., 1., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 1.],\n       [0., 0., 1., 1., 0., 0.]], dtype=float32)>"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"### StringLookup Layer","metadata":{}},{"cell_type":"code","source":"cities = ['Auckland', 'Paris', 'Paris', 'San Francisco']\nstr_lookup_layer = tf.keras.layers.StringLookup()\nstr_lookup_layer.adapt(cities)\nstr_lookup_layer([['Paris'], ['Auckland'], ['Auckland'], ['Montreal']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:30:09.051751Z","iopub.execute_input":"2026-01-20T14:30:09.052053Z","iopub.status.idle":"2026-01-20T14:30:09.085127Z","shell.execute_reply.started":"2026-01-20T14:30:09.052032Z","shell.execute_reply":"2026-01-20T14:30:09.084118Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\narray([[1],\n       [3],\n       [3],\n       [0]])>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"str_lookup_layer = tf.keras.layers.StringLookup(num_oov_indices= 5)\nstr_lookup_layer.adapt(cities)\nstr_lookup_layer([['Paris'], ['Auckland'], ['Foo'], ['Bar'], ['Baz']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:30:46.950851Z","iopub.execute_input":"2026-01-20T14:30:46.951174Z","iopub.status.idle":"2026-01-20T14:30:46.967531Z","shell.execute_reply.started":"2026-01-20T14:30:46.951152Z","shell.execute_reply":"2026-01-20T14:30:46.966355Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\narray([[5],\n       [7],\n       [4],\n       [3],\n       [4]])>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"str_lookup_layer = tf.keras.layers.StringLookup(output_mode= 'one_hot')\nstr_lookup_layer.adapt(cities)\nstr_lookup_layer([['Paris'], ['Auckland'], ['Auckland'], ['Montreal']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:31:17.780697Z","iopub.execute_input":"2026-01-20T14:31:17.780990Z","iopub.status.idle":"2026-01-20T14:31:17.797739Z","shell.execute_reply.started":"2026-01-20T14:31:17.780971Z","shell.execute_reply":"2026-01-20T14:31:17.796758Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(4, 4), dtype=int64, numpy=\narray([[0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0]])>"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"ids = [123, 456, 789]\nint_lookup_layer = tf.keras.layers.IntegerLookup()\nint_lookup_layer.adapt(ids)\nint_lookup_layer([[123], [456], [123], [111]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:31:32.967743Z","iopub.execute_input":"2026-01-20T14:31:32.968076Z","iopub.status.idle":"2026-01-20T14:31:32.994468Z","shell.execute_reply.started":"2026-01-20T14:31:32.968050Z","shell.execute_reply":"2026-01-20T14:31:32.993313Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\narray([[3],\n       [2],\n       [3],\n       [0]])>"},"metadata":{}}],"execution_count":56},{"cell_type":"markdown","source":"### Hashing Layer","metadata":{}},{"cell_type":"code","source":"hashing_layer = tf.keras.layers.Hashing(num_bins= 10)\nhashing_layer([['Paris'], ['Tokyo'], ['Auckland'], ['Montreal']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:34:29.426385Z","iopub.execute_input":"2026-01-20T14:34:29.426637Z","iopub.status.idle":"2026-01-20T14:34:29.434746Z","shell.execute_reply.started":"2026-01-20T14:34:29.426617Z","shell.execute_reply":"2026-01-20T14:34:29.433880Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\narray([[0],\n       [1],\n       [9],\n       [1]])>"},"metadata":{}}],"execution_count":57},{"cell_type":"markdown","source":"### Encoding Categorical Features Using Embeddings","metadata":{}},{"cell_type":"code","source":"tf.random.set_seed(42)\nembedding_layer = tf.keras.layers.Embedding(input_dim= 5, output_dim= 2)\nembedding_layer(np.array([2, 4, 2]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:51:35.981116Z","iopub.execute_input":"2026-01-20T14:51:35.981369Z","iopub.status.idle":"2026-01-20T14:51:36.023032Z","shell.execute_reply.started":"2026-01-20T14:51:35.981349Z","shell.execute_reply":"2026-01-20T14:51:36.022301Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\narray([[ 0.01969345,  0.01732457],\n       [-0.04321727,  0.00143442],\n       [ 0.01969345,  0.01732457]], dtype=float32)>"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"tf.random.set_seed(42)\nocean_prox = ['<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND']\nstr_lookup_layer = tf.keras.layers.StringLookup()\nstr_lookup_layer.adapt(ocean_prox)\nlookup_and_embed = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(shape= [], dtype= tf.string),\n    str_lookup_layer,\n    tf.keras.layers.Embedding(input_dim= str_lookup_layer.vocabulary_size(),\n                              output_dim= 2)\n])\nlookup_and_embed(np.array(['<1H OCEAN', 'ISLAND', '<1H OCEAN']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:52:33.502271Z","iopub.execute_input":"2026-01-20T14:52:33.502548Z","iopub.status.idle":"2026-01-20T14:52:33.549556Z","shell.execute_reply.started":"2026-01-20T14:52:33.502529Z","shell.execute_reply":"2026-01-20T14:52:33.548512Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\narray([[-0.04645429,  0.04505834],\n       [-0.01421032, -0.00461551],\n       [-0.04645429,  0.04505834]], dtype=float32)>"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"tf.random.set_seed(42)\nnp.random.seed(42)\nX_train_num = np.random.rand(10_000, 8)\nX_train_cat = np.random.choice(ocean_prox, size= 10_000).astype(object)\ny_train = np.random.rand(10_000, 1)\nX_valid_num = np.random.rand(2_000, 8)\nX_valid_cat = np.random.choice(ocean_prox, size= 2_000).astype(object)\ny_valid = np.random.rand(2_000, 1)\n\nnum_input = tf.keras.layers.Input(shape= [8], name= 'num')\ncat_input = tf.keras.layers.Input(shape= [], dtype= tf.string, name= 'cat')\ncat_embeddings = lookup_and_embed(cat_input) \nencoded_inputs = tf.keras.layers.concatenate([num_input, cat_embeddings])\noutputs = tf.keras.layers.Dense(1)(encoded_inputs)\nmodel = tf.keras.models.Model(inputs= [num_input, cat_input], outputs= [outputs])\nmodel.compile(loss= 'mse', optimizer= 'sgd')\nhistory = model.fit((X_train_num, X_train_cat), y_train, epochs= 5,\n                    validation_data= ((X_valid_num, X_valid_cat), y_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:54:03.125222Z","iopub.execute_input":"2026-01-20T14:54:03.125474Z","iopub.status.idle":"2026-01-20T14:54:06.629790Z","shell.execute_reply.started":"2026-01-20T14:54:03.125453Z","shell.execute_reply":"2026-01-20T14:54:06.628390Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2619 - val_loss: 0.1127\nEpoch 2/5\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1074 - val_loss: 0.0934\nEpoch 3/5\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0914 - val_loss: 0.0866\nEpoch 4/5\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0856 - val_loss: 0.0842\nEpoch 5/5\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0833 - val_loss: 0.0833\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"### Text Preprocessing","metadata":{}},{"cell_type":"code","source":"train_data = ['To be', '!(to be)', 'That\\'s the question', 'Be, be, be.']\ntext_vec_layer = tf.keras.layers.TextVectorization()   # basically tokenize and one-hot\ntext_vec_layer.adapt(train_data)\ntext_vec_layer(['Be good!', 'Question: be or be?'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T15:02:15.255700Z","iopub.execute_input":"2026-01-20T15:02:15.255989Z","iopub.status.idle":"2026-01-20T15:02:15.314685Z","shell.execute_reply.started":"2026-01-20T15:02:15.255968Z","shell.execute_reply":"2026-01-20T15:02:15.313550Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 4), dtype=int64, numpy=\narray([[2, 1, 0, 0],\n       [6, 2, 1, 2]])>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"text_vec_layer = tf.keras.layers.TextVectorization(ragged= True)\ntext_vec_layer.adapt(train_data)\ntext_vec_layer(['Be good!', 'Question: be or be?'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T15:18:15.874855Z","iopub.execute_input":"2026-01-20T15:18:15.875202Z","iopub.status.idle":"2026-01-20T15:18:15.895835Z","shell.execute_reply.started":"2026-01-20T15:18:15.875178Z","shell.execute_reply":"2026-01-20T15:18:15.894974Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"<tf.RaggedTensor [[2, 1], [6, 2, 1, 2]]>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"text_vec_layer = tf.keras.layers.TextVectorization(output_mode= 'tf_idf')\ntext_vec_layer.adapt(train_data)\ntext_vec_layer(['Be good!', 'Question: be or be?'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T15:18:29.274355Z","iopub.execute_input":"2026-01-20T15:18:29.274634Z","iopub.status.idle":"2026-01-20T15:18:29.341293Z","shell.execute_reply.started":"2026-01-20T15:18:29.274614Z","shell.execute_reply":"2026-01-20T15:18:29.340285Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\narray([[0.96725637, 0.6931472 , 0.        , 0.        , 0.        ,\n        0.        ],\n       [0.96725637, 1.3862944 , 0.        , 0.        , 0.        ,\n        1.0986123 ]], dtype=float32)>"},"metadata":{}}],"execution_count":64},{"cell_type":"markdown","source":"## Using Pretrained Language Model Components","metadata":{}},{"cell_type":"code","source":"import tensorflow_hub as hub\n\nhub_layer = hub.KerasLayer('https://tfhub.dev/google/nnlm-en-dim50/2')\nsentence_embeddings = hub_layer(tf.constant(['To be', 'Not to be']))\nsentence_embeddings.numpy().round(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T15:26:53.720768Z","iopub.execute_input":"2026-01-20T15:26:53.721104Z","iopub.status.idle":"2026-01-20T15:27:04.868323Z","shell.execute_reply.started":"2026-01-20T15:26:53.721079Z","shell.execute_reply":"2026-01-20T15:27:04.867320Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"array([[-0.25,  0.28,  0.01,  0.1 ,  0.14,  0.16,  0.25,  0.02,  0.07,\n         0.13, -0.19,  0.06, -0.04, -0.07,  0.  , -0.08, -0.14, -0.16,\n         0.02, -0.24,  0.16, -0.16, -0.03,  0.03, -0.14,  0.03, -0.09,\n        -0.04, -0.14, -0.19,  0.07,  0.15,  0.18, -0.23, -0.07, -0.08,\n         0.01, -0.01,  0.09,  0.14, -0.03,  0.03,  0.08,  0.1 , -0.01,\n        -0.03, -0.07, -0.1 ,  0.05,  0.31],\n       [-0.2 ,  0.2 , -0.08,  0.02,  0.19,  0.05,  0.22, -0.09,  0.02,\n         0.19, -0.02, -0.14, -0.2 , -0.04,  0.01, -0.07, -0.22, -0.1 ,\n         0.16, -0.44,  0.31, -0.1 ,  0.23,  0.15, -0.05,  0.15, -0.13,\n        -0.04, -0.08, -0.16, -0.1 ,  0.13,  0.13, -0.18, -0.04,  0.03,\n        -0.1 , -0.07,  0.07,  0.03, -0.08,  0.02,  0.05,  0.07, -0.14,\n        -0.1 , -0.18, -0.13, -0.04,  0.15]], dtype=float32)"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"import subprocess\nsubprocess.run(['zip', '-r', 'working_dir.zip', '/kaggle/working'], stdout= subprocess.DEVNULL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T15:28:01.637431Z","iopub.execute_input":"2026-01-20T15:28:01.637739Z","iopub.status.idle":"2026-01-20T15:28:01.772369Z","shell.execute_reply.started":"2026-01-20T15:28:01.637714Z","shell.execute_reply":"2026-01-20T15:28:01.771214Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"CompletedProcess(args=['zip', '-r', 'working_dir.zip', '/kaggle/working'], returncode=0)"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}